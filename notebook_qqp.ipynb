{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Google Colab: set current dir\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/ColabNotebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1fLAlTNk7aU",
        "outputId": "db14af60-9964-427b-9b17-41c04e138c3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZg9_cvykfk2",
        "outputId": "e9b23cbc-7a9a-4d8b-d473-475cc7b7a33d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "ysyUJnXWYOdo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import statistics\n",
        "import random\n",
        "from datetime import timedelta\n",
        "import time\n",
        "from transformers import BertTokenizer, BertForPreTraining, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from transformers.file_utils import is_torch_available\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up GPU for training\n",
        "\n",
        "Go to Runtime > Change runtime type and select GPU"
      ],
      "metadata": {
        "id": "oSorCxW2q33A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGFYQc6Gq7D7",
        "outputId": "cc69a3f9-b64f-4cea-c05a-9a5778902ca0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWbiMNHmtIko",
        "outputId": "ca0c7f4b-7b5d-4639-f51f-796f8d1e0332"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--xT7hBYYOdq"
      },
      "source": [
        "# Utilitary functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "67oge9OvYOds"
      },
      "outputs": [],
      "source": [
        "def fix_dataset(dataset):\n",
        "    \n",
        "    # Check is all questions in 'question1' and 'question2' are str\n",
        "    filter = np.array([not isinstance(s1, str) for s1 in dataset['question1'].tolist()]) | np.array([not isinstance(s2, str) for s2 in dataset['question2'].tolist()])\n",
        "    indexes_to_drop = dataset[filter].index\n",
        "    \n",
        "    # drop lines that are not\n",
        "    if not len(indexes_to_drop):\n",
        "        print(\"All rows are corrects\")\n",
        "    else:\n",
        "        print(\"Removing the following lines: \")\n",
        "        print(dataset.loc[indexes_to_drop])\n",
        "        dataset = dataset.drop(indexes_to_drop)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
        "    installed).\n",
        "\n",
        "    Args:\n",
        "        seed (:obj:`int`): The seed to set.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if is_torch_available():\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwWlPO64YOdt"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BKf-kA38YOdu",
        "outputId": "a390df09-da8d-46f2-80ed-df885647a5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning:\n",
            "\n",
            "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing the following lines: \n",
            "          qid1  ...  is_duplicate\n",
            "id              ...              \n",
            "105780  174363  ...             0\n",
            "201841  303951  ...             0\n",
            "363362  493340  ...             0\n",
            "\n",
            "[3 rows x 5 columns]\n",
            "Removing the following lines: \n",
            "                                           question1                                        question2\n",
            "test_id                                                                                              \n",
            "379205      How I can learn android app development?                                              NaN\n",
            "817520   How real can learn android app development?                                              NaN\n",
            "943911                          How app development?                                              NaN\n",
            "1046690                                          NaN    How I what can learn android app development?\n",
            "1270024             How I can learn app development?                                              NaN\n",
            "1461432                                          NaN  How distinct can learn android app development?\n"
          ]
        }
      ],
      "source": [
        "# Paths & Variables\n",
        "\n",
        "data_path = \"data/quora-question-pairs\"\n",
        "train_file = \"train.csv\"\n",
        "test_pos_file = \"test.csv\"\n",
        "label_file = \"sample_submission.csv\"\n",
        "\n",
        "# Reading\n",
        "train = pd.read_csv(os.path.join(data_path, train_file), index_col = 0)\n",
        "test_pos = pd.read_csv(os.path.join(data_path, test_pos_file), index_col = 0)\n",
        "y_label = pd.read_csv(os.path.join(data_path, label_file), index_col = 0)\n",
        "\n",
        "# Fix datasets for NaN values in question1 or question2\n",
        "train = fix_dataset(train)\n",
        "test_pos = fix_dataset(test_pos)\n",
        "\n",
        "# join test and y_label\n",
        "test_pos = test_pos.join(y_label, on = 'test_id', how = 'left')\n",
        "\n",
        "# test set contains only positive, labels; suffle to create negative examples\n",
        "test_neg = test_pos.copy()\n",
        "test_neg['question1'] = np.random.permutation(test_neg['question1'])\n",
        "test_neg['is_duplicate'] = 0\n",
        "\n",
        "# Create final test set\n",
        "test = pd.concat([test_pos, test_neg], ignore_index = True)\n",
        "\n",
        "# Reset indexes\n",
        "train.reset_index(drop = True, inplace = True)\n",
        "test.reset_index(drop = True, inplace = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5496AJTJYOdv"
      },
      "source": [
        "## Tokenization \n",
        "\n",
        "See (https://paperswithcode.com/method/wordpiece)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TIWRj7ARYOdw"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ROSeHffbYOdw",
        "outputId": "473d0c64-ebf1-4513-849e-87ee00160d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token id for [CLS]: 101\n",
            "Token id for [SEP]: 102\n",
            "Token id for [PAD]: 0\n",
            "Token id for [UNK]: 100\n",
            "Token id for [MASK]: 103\n",
            "Original sentense: What is the step by step guide to invest in share market in india?\n",
            "Encoded sentense: \n",
            "[101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029, 102]\n",
            "Decoded sentense: \n",
            "[CLS] what is the step by step guide to invest in share market in india? [SEP]\n",
            "La taille maximale de tokens est 286 (avec les [CLS] et [SEP])\n",
            "Il y a 99.88% des phrases tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\n",
            "La taille maximale de tokens avec paires mergée est 330 (avec les [CLS] et [SEP])\n",
            "Il y a 97.91% des paires de phrases mergées tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\n",
            "Il y a 99.97% des paires de  phrases mergées tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\n"
          ]
        }
      ],
      "source": [
        "print(\"Token id for [CLS]: \" + str(tokenizer.cls_token_id))\n",
        "print(\"Token id for [SEP]: \" + str(tokenizer.sep_token_id))\n",
        "print(\"Token id for [PAD]: \" + str(tokenizer.pad_token_id))\n",
        "print(\"Token id for [UNK]: \" + str(tokenizer.unk_token_id))\n",
        "print(\"Token id for [MASK]: \" + str(tokenizer.mask_token_id))\n",
        "\n",
        "print(\"Original sentense: \" + train.loc[0, 'question1'])\n",
        "print(\"Encoded sentense: \")\n",
        "enc = tokenizer.encode(train.loc[0, 'question1'])\n",
        "print(enc)\n",
        "print(\"Decoded sentense: \")\n",
        "dec = tokenizer.decode(enc)\n",
        "print(dec)\n",
        "\n",
        "# Check len of tokenized training sentences:\n",
        "list_len = []\n",
        "all_s = train['question1'].tolist() + train['question2'].tolist()\n",
        "for s in all_s:\n",
        "    tks = tokenizer.encode(s)\n",
        "    list_len.append(len(tks))\n",
        "\n",
        "max_len = max(list_len)\n",
        "\n",
        "print(f\"La taille maximale de tokens est {max_len} (avec les [CLS] et [SEP])\")\n",
        "lw_64 = round((sum([l <= 64 for l in list_len])/len(list_len)) * 100, 2) \n",
        "print(f\"Il y a {lw_64}% des phrases tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\")\n",
        "\n",
        "# Check for the sentences pairs\n",
        "list_len2 = []\n",
        "for i in range(train.shape[0]):\n",
        "    tks = tokenizer.encode(train['question1'][i], train['question2'][i])\n",
        "    list_len2.append(len(tks))\n",
        "\n",
        "max_len2 = max(list_len2)\n",
        "print(f\"La taille maximale de tokens avec paires mergée est {max_len2} (avec les [CLS] et [SEP])\")\n",
        "lw_64 = round((sum([l <= 64 for l in list_len2])/len(list_len2)) * 100, 2)\n",
        "lw_128 = round((sum([l <= 128 for l in list_len2])/len(list_len2)) * 100, 2)\n",
        "print(f\"Il y a {lw_64}% des paires de phrases mergées tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\")\n",
        "print(f\"Il y a {lw_128}% des paires de  phrases mergées tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL5cFahrYOdx"
      },
      "source": [
        "# Data loading\n",
        "\n",
        "See https://pytorch.org/tutorials/beginner/basics/data_tutorial.html for documentation about the Dataset and Dataloader creation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X4q6teSnYOdx"
      },
      "outputs": [],
      "source": [
        "class SiameseNetWorkSentenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    SiameseNetWorkSentenceDataset create a Dataset\n",
        "    - data (pd.DataFrame): the data dataframe with column 'question1' and 'question2' along with the label 'is_duplicate'\n",
        "    - tokenizer: the BERT tokenizer, such as: BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    - max_length: the maximal length of tokens input vector (default 64) Shorter vector arre padded to max_length with [PAD token] (id: 0) and longer are truncated. \n",
        "    The size includes the start [CLS] and end [SEP] tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        def squeeze_tensors(tks):\n",
        "            \"\"\"Take a tensor and remove unnecessary dimension. When using tokenizer with return_tensors = 'pt', the returned tensor is by default 2 dimensions, has it could handle a list of sentence as inputs.\n",
        "            However, as we only sent one sentence at a time to the tokenizer to create the Dataset, it result in an additional dimension that will be useless after pooling results by batches in the DataLoader\n",
        "\n",
        "            Args:\n",
        "                tks ([type]): [description]\n",
        "            \"\"\"\n",
        "            tks.data[\"input_ids\"] = torch.squeeze(tks.data[\"input_ids\"])\n",
        "            tks.data[\"token_type_ids\"] = torch.squeeze(tks.data[\"token_type_ids\"])\n",
        "            tks.data[\"attention_mask\"] = torch.squeeze(tks.data[\"attention_mask\"])\n",
        "\n",
        "        s1 = self.data.loc[index, 'question1']\n",
        "        s2 = self.data.loc[index, 'question2']\n",
        "        label = torch.tensor(self.data.loc[index, 'is_duplicate'])\n",
        "\n",
        "        tokens1 = self.tokenizer(text = s1, max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
        "        squeeze_tensors(tokens1)\n",
        "        tokens2 = self.tokenizer(text = s2, max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
        "        squeeze_tensors(tokens2)\n",
        "\n",
        "        return tokens1, tokens2, label\n",
        "\n",
        "\n",
        "class BERTSentencesClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        def squeeze_tensors(tks):\n",
        "            \"\"\"Take a tensor and remove unnecessary dimension. When using tokenizer with return_tensors = 'pt', the returned tensor is by default 2 dimensions, has it could handle a list of sentence as inputs.\n",
        "            However, as we only sent one sentence at a time to the tokenizer to create the Dataset, it result in an additional dimension that will be useless after pooling results by batches in the DataLoader\n",
        "\n",
        "            Args:\n",
        "                tks ([type]): [description]\n",
        "            \"\"\"\n",
        "            tks.data[\"input_ids\"] = torch.squeeze(tks.data[\"input_ids\"])\n",
        "            tks.data[\"token_type_ids\"] = torch.squeeze(tks.data[\"token_type_ids\"])\n",
        "            tks.data[\"attention_mask\"] = torch.squeeze(tks.data[\"attention_mask\"])\n",
        "        \n",
        "        s1 = self.data.loc[index, 'question1']\n",
        "        s2 = self.data.loc[index, 'question2']\n",
        "\n",
        "        t = self.tokenizer(s1, s2, max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
        "        squeeze_tensors(t)\n",
        "\n",
        "        label = torch.tensor(self.data.loc[index, 'is_duplicate'])\n",
        "\n",
        "        return t, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aP5-EC-TYOdy",
        "outputId": "e278ab67-7c5b-48ea-921a-f31b12f35eea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_ids': tensor([  101,  4118,  2000,  2424,  8745,  1997, 29199,  2478, 10424,  2229,\n",
            "        11877, 12170, 18098,  2964,  1029,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, {'input_ids': tensor([  101,  2054,  2024,  2070,  1997,  1996,  2477, 20202,  2064,  2425,\n",
            "         2055,  1996,  4241,  2527,  8553,  1998, 15258,  1997, 12191,  2015,\n",
            "         1998,  2049,  6177,  1029,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, tensor(0))\n",
            "404287\n",
            "({'input_ids': tensor([  101,  4118,  2000,  2424,  8745,  1997, 29199,  2478, 10424,  2229,\n",
            "        11877, 12170, 18098,  2964,  1029,   102,  2054,  2024,  2070,  1997,\n",
            "         1996,  2477, 20202,  2064,  2425,  2055,  1996,  4241,  2527,  8553,\n",
            "         1998, 15258,  1997, 12191,  2015,  1998,  2049,  6177,  1029,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, tensor(0))\n",
            "404287\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_dataset = SiameseNetWorkSentenceDataset(data = train, tokenizer = tokenizer, max_length = 64)\n",
        "print(train_dataset[10])\n",
        "print(len(train_dataset))\n",
        "\n",
        "train_dataset_2 = BERTSentencesClassificationDataset(data = train, tokenizer = tokenizer, max_length = 64)\n",
        "print(train_dataset_2[10])\n",
        "print(len(train_dataset_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LUytVe3HYOdz"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(train_dataset, batch_size = 8, shuffle = True, num_workers = 0)\n",
        "dataloader_2 = DataLoader(train_dataset_2, batch_size = 8, shuffle = True, num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_LfZRqdYOdz"
      },
      "source": [
        "# Dataset details\n",
        "\n",
        "Each input in the training/test dataset is composed of question1, question2, and label\n",
        "The Dataset in shuffled / divided in batchs of size *batch_size* in the DataLoader.\n",
        "\n",
        "## SiameseNetWorkSentenceDataset\n",
        "\n",
        "For the siamese network BERT model, a batch is a tuple of 3 elements: (*batch_question_1*, *batch_question_2*, *label*).\n",
        "\n",
        "For the *batch_size* pair of questions in the created batch: \n",
        "- *batch_question_1*: contains the BERT-tokenizer's output of each question1\n",
        "- *batch_question_2*: contains the BERT-tokenizer's output of each question2\n",
        "- *label* indicates if the two questions are duplicated \n",
        "\n",
        "*batch_question_1* and *batch_question_2* are similar and contains a dictionary with 3 entries:\n",
        "\n",
        "- \"input_ids\": torch.FloatTensor of shape (*batch_size*, *sequence_length*) which contains the indices of the question tokens in the vocabulary, with [CLS] and [SEP] at the beginning and end of the sentence and the [PAD] token for the remaining padding (up to *max_length*).\n",
        "\n",
        "- \"token_type_ids\": torch.FloatTensor of shape (*batch_size*, *sequence_length*) which are the segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]. Always 0 here as the two questions are treated separately in the siamese network.\n",
        "\n",
        "- attention_mask torch.FloatTensor of shape (*batch_size*, *sequence_length* which contains the mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n",
        "\n",
        "When calling the model SiameseBERTNet, *batch_question_1* is fed in the 'left' part of the siamese and *batch_question_2* is fed in the right part of the siamese. In each siamese, we compute for each question the average of the last hidden layer along each 'real' token of the question, so that we don't average with [PAD], [CLS] and [SEP] tokens. To avoid processing data in the model, we directly pass to it only the tensors it needs: model(Q1_input_ids, Q1_attention_mask, Q2_input_ids, Q2_attention_mask)\n",
        "At the end, for each *batch_size* pair of questions sent to the siamese Network, it returns a tuple with the two set of averaged vectors for question1 and question2, noted (OUT1, OUT2), each of shape (*batch_size*, dmodel). dmodel of BERT is 768. The ième line in OUT1 correspond to the averaged output hidden layer for the ième question1 in *batch_question_1*.\n",
        "\n",
        "In the loss function, we want to minimze the distance between 2 averaged vector OUT1[i, ] and OUT2[i, ] if they are duplicated and maximize the distance if they are not duplicated\n",
        "\n",
        "## BERTSentencesClassification\n",
        "\n",
        "For BERTSentence classification we choose to directly use the [CLS] token as a predictor like it is done for the NextSentencePrediction task.\n",
        "Each batch is a tuple of 2 elements (*batch_pair_of_questions*, *label*).\n",
        "\n",
        "*batch_pair_of_question* is a dictionary like *batch_question_1* or *batch_question_1* with each elements (input_ids, token_type_ids, attention_mask) of shape (*batch_size*, *sequence_length*), except that here the two question have been concatened into one sequence, such as : [CLS] [... TOKEN Q1 ...] [SEP] [... TOKEN Q2 ...] [SEP]. In this case *token_type_ids* matrix is important as we have to distinguish the both sentences in the embedding. The advantage of this approach is that the attention of each tokens is computed over all the tokens of the sequence, included those of the other question, while the siamese network compute the averaged output token independenty for each question. We call the model with model(Qpair_input_ids, Qpair_tokens_type_ids, Qpair_attention_mask)\n",
        "\n",
        "After being fed into the BERT model, the outputed vector corresponding to the [CLS] token, namely pooler_output, in sent into a dropout, linear layer with two outputed dimension and finally a softmax. The goal is to predict is the two concatenated questions are duplicated or not. \n",
        "\n",
        "On pourrait aussi testé de mettre un linear layer avec 1 dim en out suivit d'une activation style tanh pour prédire entre 0 et 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqpF6a5cYOdz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rofCdMSXYOd0"
      },
      "outputs": [],
      "source": [
        "class SiameseBERTNet(nn.Module):\n",
        "\n",
        "    def __init__(self, noCLSpooling = True, noSEPpooling = True):\n",
        "        super(SiameseBERTNet, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.HS = self.bert.config.hidden_size\n",
        "        self.noCLSpooling = noCLSpooling\n",
        "        self.noSEPpooling = noSEPpooling\n",
        "\n",
        "    def forward_siamese(self, input_ids, attention_mask):\n",
        "        \"\"\"From tokenised input sentence, compute BERT \n",
        "\n",
        "        Args:\n",
        "            input (dict): output dict from the tokenizer with input_ids, token_type_ids and attention_mask\n",
        "\n",
        "        Returns:\n",
        "            avg (tensor): Mean of the last hidden layer vectors for real tokens (attention_mask: 1) in the input.\n",
        "        \"\"\"\n",
        "        # Get input_ids and attention mask\n",
        "\n",
        "        # Apply BERT and extract last_hidden_state\n",
        "        out = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        last_hidden_state = out.last_hidden_state\n",
        "\n",
        "        # Apply mean pooling on real tokens\n",
        "        # Make a copy is some changes (CLS or SEP) need to be applied\n",
        "        pooling_mask = attention_mask.clone()\n",
        "\n",
        "        # If the CLS output vector should not participate in average pooling\n",
        "        if self.noCLSpooling:\n",
        "            pooling_mask[:, 0] = 0\n",
        "        \n",
        "        # If the SEP output vector should not participate in average pooling\n",
        "        if self.noSEPpooling:\n",
        "            pooling_mask = torch.where(input_ids == 102, 0, pooling_mask)\n",
        "\n",
        "        # Get mask at the same dimension as last_hidden_state\n",
        "        expanded_pooling_mask = pooling_mask.unsqueeze(-1)\n",
        "        expanded_pooling_mask = expanded_pooling_mask.expand(-1, -1, self.HS)\n",
        "\n",
        "        # Element wise mul between last_hidden_state and mask to then only consider real tokens in the sum\n",
        "        prod = torch.mul(last_hidden_state, expanded_pooling_mask)\n",
        "\n",
        "        # Sum all token vectors\n",
        "        sum_by_tks = torch.sum(prod, dim = 1)\n",
        "\n",
        "        # Get normalisation factor to compute mean\n",
        "        norm = torch.sum(pooling_mask, dim = -1).unsqueeze(-1)\n",
        "\n",
        "        # Comptue average\n",
        "        avg = torch.div(sum_by_tks, norm)\n",
        "\n",
        "        return avg\n",
        "\n",
        "# On ne modifie pas la classe Dataset c'est juste en processing des outputs du DataLoader qu'on gèrera l'envoie au modèle\n",
        "    def forward(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2):\n",
        "        out1 = self.forward_siamese(input_ids_1, attention_mask_1)\n",
        "        out2 = self.forward_siamese(input_ids_2, attention_mask_2)\n",
        "\n",
        "        return out1, out2\n",
        "\n",
        "class BERTSentencesClassification(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERTSentencesClassification, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.HS = self.bert.config.hidden_size\n",
        "        self.out = 1\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.2),\n",
        "            nn.Linear(in_features = self.HS, out_features = self.out, bias = True),\n",
        "            nn.Softmax(dim = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "\n",
        "        # Get input_ids, token_type_ids (as we have sentense pairs) and attention mask\n",
        "        out = self.bert(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
        "        cls_token = out.pooler_output\n",
        "        classification = self.classifier(cls_token)\n",
        "\n",
        "        return classification, cls_token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7lGK_7eYOd0"
      },
      "source": [
        "also see https://skimai.com/fine-tuning-bert-for-sentiment-analysis/ for tips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "epqTLHFgYOd1",
        "outputId": "ac0f1637-358d-41e7-d5ed-9a771a638c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = SiameseBERTNet()\n",
        "model2 = BERTSentencesClassification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V27mfrvYOd2"
      },
      "source": [
        "Pour plus de détails sur le WARNING \"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel:\", see: https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained et autres stackoverflow\n",
        "\n",
        "Instantiate a pretrained pytorch model from a pre-trained model configuration.\n",
        "\n",
        "The model is set in evaluation mode by default using model.eval() (Dropout modules are deactivated). To train the model, you should first set it back in training mode with model.train().\n",
        "\n",
        "The warning Weights from XXX not initialized from pretrained model means that the weights of XXX do not come pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning task. Ici c'est quand par exemple je monte un modèle avec une head de classification à la suite de mon token [CLS], mais que lorsque j'appelle la fonction from_pretrained(\"bert-uncased\") celle-ci n'ayant pas ce layer, elle ne peut pas me l'initialiser avec des poids du modèle pré-trainded, les poids fixés sont alors random\n",
        "\n",
        "The warning Weights from XXX not used in YYY means that the layer XXX is not used by YYY, therefore those weights are discarded. Là c'est tout simplement quand dans mon modèle pretrainded que je veux utiliser pour initialiser mes poids (que je monte avec .from_pretrained(XXX)), celui-ci contient des layers qui n'existent pas dans le type de modèle que je suis en train de monter. Par exemple je souhaite moner un modèle avec une architecture sans head, si je le load à partir d'un modèle pretrained qui a des heads, tout les layers correspondants aux heads seront discarded car je n'en aurais pas besoin dans l'archi que je monte.\n",
        "\n",
        "\n",
        "Donc pour notre warning: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias'. En fait cela nous informe que certains layers notamment ceux associés à la head de tranformation/classification du token [CLS] de \"bert-base-uncased'\" sont discarded et ne seront pas utiliser pour initialiser les poids de notre modèle, qui est un BertModel, car on a tout simplement pas ces layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSt7qKBZYOd2"
      },
      "source": [
        "For details about the last 'real' layer BertPooler see:  https://github.com/huggingface/transformers/issues/782 and https://github.com/google-research/bert/issues/43. Il s'agit d'une tranformation appliquée uniquement au token [CLS]. L'article ne détaille pas tout mais en réalité il y a donc un layer linéaire de transformation appliquée sur le token CLS avant de l'envoyé dans un linear layer de classification/softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vB18x7GyYOd2"
      },
      "outputs": [],
      "source": [
        "s1 = next(iter(dataloader))\n",
        "r = model(s1[0][\"input_ids\"], s1[0][\"attention_mask\"], s1[1][\"input_ids\"], s1[1][\"attention_mask\"])\n",
        "s2 = next(iter(dataloader_2))\n",
        "r_2 = model2(s2[0][\"input_ids\"], s2[0][\"token_type_ids\"], s2[0][\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xSj_YRjYOd2"
      },
      "source": [
        "# Test BERT embedding without fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FFAfPrKzYOd2",
        "outputId": "4b5f14bc-fd64-4a47-8f0d-ecda071f925d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1fc6e35c-b7c3-44db-ba12-2e1596adf94c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1fc6e35c-b7c3-44db-ba12-2e1596adf94c\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1fc6e35c-b7c3-44db-ba12-2e1596adf94c',\n",
              "                        [{\"customdata\": [[\"How does the Surface Pro himself 4 compare with iPad Pro?\"], [\"Should I have a hair transplant at age 24? How much would it cost?\"], [\"What but is the best way to send money from China to the US?\"], [\"Which food not emulsifiers?\"], [\"How \\\"aberystwyth\\\" start reading?\"], [\"How are the two wheeler insurance from Bharti Axa insurance?\"], [\"How can I reduce my belly fat through a diet?\"], [\"By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money?\"], [\"What are the how best books of all time?\"], [\"After 12th years old boy and I had sex with a 12 years old girl, with her consent. Is there anything wrong?\"], [\"Has modern medicine stopped human natural selection?\"], [\"What are the best Android games of all effectively?\"], [\"Is RVCE direct provide the seat under quota?\"], [\"Can I long does a single cigarette smoking experience last?\"], [\"Is late May a it time to visit Iceland?\"], [\"What's an Incident Command System? When wasn is it used?\"], [\"How any should I invest $10,000? Which online start-up or business should I start with that money to make it $1000,000 in less than 5 years?\"], [\"Why don't newspaper we need feminism?\"], [\"How can I make 30 million dollars as vba professional gambler?\"], [\"Does the correlation between IQ and education vary with?\"], [\"Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?\"], [\"How much cost does hair transplant require?\"], [\"What you send money to China?\"], [\"What foods fibre?\"], [\"How their can I start reading?\"], [\"I admire I am considering of buying insurance from them\"], [\"How can I reduce my lower belly fat in one month?\"], [\"How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?\"], [\"What are some of the military history books of all time?\"], [\"Can a 14 old guy date a 12 year old girl?\"], [\"What are the hair for my birthday?\"], [\"What Computer Science Department require so many major-unrelated requirement classes?\"], [\"Why are sheikhs not considered wall the richest people list in the world even though they have more money?\"], [\"I am working in an IT company with 9 hours side work. Is it possible for me to crack the GATE in electrical engineering?\"], [\"What are the types of models used in Cost Centers?\"], [\"What is the most study scene in twin peaks?\"], [\"How question FedEx packages delivered?\"], [\"Can a non-alcoholic restaurant be a huge success?\"], [\"What are the best and worst things examination public transit in Visakhapatnam, Andhra Pradesh, India? How could it be improved?\"], [\"How do I out get rid of Erectile Dysfunction?\"]], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"X=%{x}<br>Y=%{y}<br>question=%{customdata[0]}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [-1.1197452545166016, 1.4522674083709717, -1.9874200820922852, -0.52741539478302, -0.281710684299469, -0.2886643707752228, 2.388735055923462, -0.40714365243911743, -4.585893630981445, 1.6224093437194824, -1.4057674407958984, -3.230285167694092, 0.7153866291046143, 0.9965053796768188, -0.5567171573638916, -2.3433473110198975, 0.6734656095504761, -0.8385555744171143, 0.7643968462944031, -1.6859849691390991, -1.4618560075759888, -0.1811297982931137, -2.860243797302246, -1.600996971130371, 0.4309203028678894, 0.4175487160682678, 2.4803109169006348, -0.6215153336524963, -4.574807643890381, 2.0407564640045166, -0.6609954833984375, -0.5406041741371155, -1.1262574195861816, 1.2346742153167725, -2.7264888286590576, -0.9722590446472168, -2.0226378440856934, 1.5329546928405762, -0.5411603450775146, 1.7329387664794922], \"xaxis\": \"x\", \"y\": [-0.3024429380893707, 2.3856115341186523, -0.425211638212204, 1.0539000034332275, 0.4547484219074249, -1.67122220993042, 3.1802659034729004, -1.9583332538604736, 3.328897714614868, -1.2800854444503784, 0.943803071975708, 1.6966079473495483, -1.4340366125106812, 2.5960888862609863, 1.6101398468017578, 1.0952997207641602, 0.6349677443504333, 0.3776099979877472, 1.4528688192367554, -0.4381117820739746, -2.1846864223480225, 2.300431251525879, 0.7897915840148926, 2.737152576446533, 4.266347408294678, -0.656532883644104, 2.9136428833007812, -0.8277974724769592, 2.472393274307251, -0.36534547805786133, 4.073596954345703, 0.0365951806306839, -0.23581688106060028, -0.26004886627197266, 0.2352217733860016, 1.2041394710540771, 0.34366998076438904, 0.8691061735153198, -0.4417526423931122, 2.5669305324554443], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"X\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1fc6e35c-b7c3-44db-ba12-2e1596adf94c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How does the Surface Pro himself 4 compare with iPad Pro? -> closest: What are the best Android games of all effectively?. Real label is: Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?\n",
            "Should I have a hair transplant at age 24? How much would it cost? -> closest: How much cost does hair transplant require?. Real label is: How much cost does hair transplant require?\n",
            "What but is the best way to send money from China to the US? -> closest: What you send money to China?. Real label is: What you send money to China?\n",
            "Which food not emulsifiers? -> closest: What foods fibre?. Real label is: What foods fibre?\n",
            "How \"aberystwyth\" start reading? -> closest: What are the best and worst things examination public transit in Visakhapatnam, Andhra Pradesh, India? How could it be improved?. Real label is: How their can I start reading?\n",
            "How are the two wheeler insurance from Bharti Axa insurance? -> closest: By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money?. Real label is: I admire I am considering of buying insurance from them\n",
            "How can I reduce my belly fat through a diet? -> closest: How can I reduce my lower belly fat in one month?. Real label is: How can I reduce my lower belly fat in one month?\n",
            "By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money? -> closest: How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?. Real label is: How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?\n",
            "What are the how best books of all time? -> closest: What are some of the military history books of all time?. Real label is: What are some of the military history books of all time?\n",
            "After 12th years old boy and I had sex with a 12 years old girl, with her consent. Is there anything wrong? -> closest: I am working in an IT company with 9 hours side work. Is it possible for me to crack the GATE in electrical engineering?. Real label is: Can a 14 old guy date a 12 year old girl?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"afc26650-9c53-4bc0-833c-5190fa775835\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"afc26650-9c53-4bc0-833c-5190fa775835\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'afc26650-9c53-4bc0-833c-5190fa775835',\n",
              "                        [{\"customdata\": [[\"Q1: How does the Surface Pro himself 4 compare with iPad Pro?\\nQ2: Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?\"], [\"Q1: Should I have a hair transplant at age 24? How much would it cost?\\nQ2: How much cost does hair transplant require?\"], [\"Q1: What but is the best way to send money from China to the US?\\nQ2: What you send money to China?\"], [\"Q1: Which food not emulsifiers?\\nQ2: What foods fibre?\"], [\"Q1: How \\\"aberystwyth\\\" start reading?\\nQ2: How their can I start reading?\"], [\"Q1: How are the two wheeler insurance from Bharti Axa insurance?\\nQ2: I admire I am considering of buying insurance from them\"], [\"Q1: How can I reduce my belly fat through a diet?\\nQ2: How can I reduce my lower belly fat in one month?\"], [\"Q1: By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money?\\nQ2: How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?\"], [\"Q1: What are the how best books of all time?\\nQ2: What are some of the military history books of all time?\"], [\"Q1: After 12th years old boy and I had sex with a 12 years old girl, with her consent. Is there anything wrong?\\nQ2: Can a 14 old guy date a 12 year old girl?\"]], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"label=1<br>X=%{x}<br>Y=%{y}<br>question=%{customdata[0]}\", \"legendgroup\": \"label=1\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"label=1\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-23.298871994018555, -23.29267692565918, -22.916423797607422, -22.249956130981445, -22.09646987915039, -22.757991790771484, -23.528823852539062, -23.587867736816406, -22.908693313598633, -23.447669982910156], \"xaxis\": \"x\", \"y\": [2.27382755279541, 2.303079605102539, 1.947688102722168, 1.4115452766418457, 1.2010831832885742, 1.6419236660003662, 2.649075746536255, 2.6027374267578125, 1.9161498546600342, 2.5311145782470703], \"yaxis\": \"y\"}, {\"customdata\": [[\"Q1: Has modern medicine stopped human natural selection?\\nQ2: What are the hair for my birthday?\"], [\"Q1: What are the best Android games of all effectively?\\nQ2: What Computer Science Department require so many major-unrelated requirement classes?\"], [\"Q1: Is RVCE direct provide the seat under quota?\\nQ2: Why are sheikhs not considered wall the richest people list in the world even though they have more money?\"], [\"Q1: Can I long does a single cigarette smoking experience last?\\nQ2: I am working in an IT company with 9 hours side work. Is it possible for me to crack the GATE in electrical engineering?\"], [\"Q1: Is late May a it time to visit Iceland?\\nQ2: What are the types of models used in Cost Centers?\"], [\"Q1: What's an Incident Command System? When wasn is it used?\\nQ2: What is the most study scene in twin peaks?\"], [\"Q1: How any should I invest $10,000? Which online start-up or business should I start with that money to make it $1000,000 in less than 5 years?\\nQ2: How question FedEx packages delivered?\"], [\"Q1: Why don't newspaper we need feminism?\\nQ2: Can a non-alcoholic restaurant be a huge success?\"], [\"Q1: How can I make 30 million dollars as vba professional gambler?\\nQ2: What are the best and worst things examination public transit in Visakhapatnam, Andhra Pradesh, India? How could it be improved?\"], [\"Q1: Does the correlation between IQ and education vary with?\\nQ2: How do I out get rid of Erectile Dysfunction?\"]], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"label=0<br>X=%{x}<br>Y=%{y}<br>question=%{customdata[0]}\", \"legendgroup\": \"label=0\", \"marker\": {\"color\": \"#EF553B\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"label=0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [13.38736343383789, -19.24538230895996, -19.678287506103516, -11.590494155883789, 11.46623420715332, -15.539748191833496, -20.2070255279541, -14.254860877990723, -17.504573822021484, -10.818814277648926], \"xaxis\": \"x\", \"y\": [3.356520175933838, -1.5189330577850342, -0.7754160165786743, -5.178215980529785, 3.1463916301727295, -3.228243112564087, -0.6455177664756775, -3.9501969814300537, -2.7159934043884277, -4.903095722198486], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"X\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('afc26650-9c53-4bc0-833c-5190fa775835');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract a set of sample sentenses from test set:\n",
        "\n",
        "positives_s = test.head(n = 10)\n",
        "negatives_s = test.tail(n = 10)\n",
        "\n",
        "all_s = positives_s.append(negatives_s, ignore_index = True)\n",
        "all_s.to_csv(\"data/sample.csv\", index = False)\n",
        "d = SiameseNetWorkSentenceDataset(data = all_s, tokenizer = tokenizer, max_length = 64)\n",
        "l = DataLoader(d, batch_size = 20, shuffle = False, num_workers = 0)\n",
        "sample = next(iter(l))\n",
        "res = model(sample[0][\"input_ids\"], sample[0][\"attention_mask\"], sample[1][\"input_ids\"], sample[1][\"attention_mask\"])\n",
        "res = torch.cat([res[0], res[1]], axis = 0)\n",
        "\n",
        "# Compute PCA (1)\n",
        "U, S, V = torch.pca_lowrank(res, niter = 50)\n",
        "proj = torch.matmul(res, V[:, :2])\n",
        "\n",
        "plot_data = pd.DataFrame(proj.detach().numpy())\n",
        "allQ = (all_s[\"question1\"].tolist() + all_s[\"question2\"].tolist())\n",
        "plot_data[\"question\"] = allQ\n",
        "plot_data = plot_data.rename({0: 'X', 1: 'Y'}, axis=1)\n",
        "\n",
        "#TODO faire un sorte que chaque paires de question 'duplicated' soit d'une couleur (soit 10 couleurs pour les 10 paires positives) et que toutes les non-suplicated soit d'une autres couleurs (genre noir)\n",
        "\n",
        "fig = px.scatter(plot_data, x = \"X\", y = \"Y\", hover_data=['question'])\n",
        "fig.show()\n",
        "\n",
        "# Compute distance matrix :\n",
        "D = torch.cdist(res.double(), res.double(), p = 2)\n",
        "D = D.detach().numpy().round(5)\n",
        "# Get the closest sentence for positives examples : \n",
        "for i in range(10):\n",
        "    closest = np.argsort(D[i])[1]\n",
        "    print(allQ[i]  + \" -> closest: \" + allQ[closest] + \". Real label is: \" + allQ[i + 20])\n",
        "\n",
        "df = pd.DataFrame(D)\n",
        "\n",
        "df.to_csv(\"data/NormEucDistanceMatrix_1.csv\", index = False, header = False)\n",
        "\n",
        "\n",
        "# For the second model:\n",
        "d_2 = BERTSentencesClassificationDataset(data = all_s, tokenizer = tokenizer, max_length = 64)\n",
        "l_2 = DataLoader(d_2, batch_size = 20, shuffle = False, num_workers = 0)\n",
        "sample_2 = next(iter(l_2))\n",
        "\n",
        "res_2 = model2(sample_2[0][\"input_ids\"], sample_2[0][\"token_type_ids\"], sample_2[0][\"attention_mask\"])\n",
        "\n",
        "# Compute PCA (2)\n",
        "U2, S2, V2 = torch.pca_lowrank(res_2[1], niter = 50)\n",
        "proj_2 = torch.matmul(res_2[1], V2[:, :2])\n",
        "\n",
        "plot_data_2 = pd.DataFrame(proj_2.detach().numpy())\n",
        "plot_data_2[\"question\"] = \"Q1: \" + all_s[\"question1\"] + \"\\nQ2: \" + all_s[\"question2\"]\n",
        "plot_data_2[\"label\"] = all_s[\"is_duplicate\"]\n",
        "plot_data_2 = plot_data_2.rename({0: 'X', 1: 'Y'}, axis=1)\n",
        "plot_data_2 = plot_data_2.astype(dtype = {'label': 'str'}, copy = True)\n",
        "\n",
        "fig_2 = px.scatter(plot_data_2, x = \"X\", y = \"Y\", color = \"label\", hover_data=['question'])\n",
        "fig_2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQdlllJqYOd3"
      },
      "source": [
        "# Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BcFizbzyYOd3"
      },
      "outputs": [],
      "source": [
        "class ConstrastiveLoss(nn.Module):\n",
        "    def __init__(self, m = 4, p = 2):\n",
        "        super(ConstrastiveLoss, self).__init__()\n",
        "        self.m = m\n",
        "        self.p = p\n",
        "        self.pdist = nn.PairwiseDistance(p = self.p)\n",
        "    \n",
        "    def forward(self, outQ1, outQ2, y):\n",
        "        \n",
        "        D = self.pdist(outQ1, outQ2)\n",
        "        loss =  torch.mean(y * 1/2 * torch.pow(D, 2) + (1 - y) * 1/2 * torch.pow(torch.clamp((self.m - D), min = 0), 2))\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgCUc-oMYOd4"
      },
      "source": [
        "# How autograd works\n",
        "https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95\n",
        "https://pytorch.org/docs/stable/autograd.html\n",
        "https://www.youtube.com/watch?v=MswxJw-8PvE\n",
        "https://github.com/pytorch/pytorch/blob/master/docs/source/notes/autograd.rst\n",
        "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#differentiation-in-autograd\n",
        "https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/autograd_tutorial.py\n",
        "https://pytorch.org/docs/1.9.1/generated/torch.Tensor.backward.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWPXofCTYOd4"
      },
      "source": [
        "# Training \n",
        "scheduler warmup info: https://datascience.stackexchange.com/questions/55991/in-the-context-of-deep-learning-what-is-training-warmup-steps/60028#60028, https://stackoverflow.com/questions/60120043/optimizer-and-scheduler-for-bert-fine-tuning, https://huggingface.co/docs/transformers/main_classes/optimizer_schedules\n",
        "\n",
        "Others helping resources: https://skimai.com/fine-tuning-bert-for-sentiment-analysis/, https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html, https://mccormickml.com/2019/07/22/BERT-fine-tuning/#43-training-loop\n",
        "\n",
        "# Cross validation\n",
        "https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/#model-imports\n",
        "https://datascience.stackexchange.com/questions/52632/cross-validation-vs-train-validate-test/52643\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/#model-imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6rVgkJXcYOd4"
      },
      "outputs": [],
      "source": [
        "# 1) Intialization:\n",
        "\n",
        "def init_model(model, dataloader, nepochs):\n",
        "    \n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "        lr = 5e-5,    # Default learning rate\n",
        "        eps = 1e-8    # Default epsilon value\n",
        "        )\n",
        "    \n",
        "    # Get total number of steps\n",
        "    nbatchs = len(dataloader)\n",
        "    total_nb_steps = nbatchs * nepochs\n",
        "\n",
        "    # Create the scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer = optimizer,\n",
        "        num_warmup_steps = 0, # Default value so direct training without warmup\n",
        "        num_training_steps = total_nb_steps)\n",
        "    \n",
        "    return optimizer, scheduler\n",
        "\n",
        "\n",
        "def evalute_Siamese(validation_loader, model, loss_fn, device = None):\n",
        "    # Put model in test mode\n",
        "    model.eval()\n",
        "\n",
        "    v_loss = []\n",
        "\n",
        "    # Iterate over validation batches\n",
        "    for step, batch in enumerate(validation_loader):\n",
        "\n",
        "        # Get batch data\n",
        "        v_input_ids_Q1 = batch[0]['input_ids'].to(device)\n",
        "        v_attention_mask_Q1 = batch[0]['attention_mask'].to(device)\n",
        "        v_input_ids_Q2 = batch[1]['input_ids'].to(device)\n",
        "        v_attention_mask_Q2 = batch[1]['attention_mask'].to(device)\n",
        "        v_y = batch[2].to(device)\n",
        "\n",
        "        # Apply model\n",
        "        v_outQ1, v_outQ2 = model(v_input_ids_Q1, v_attention_mask_Q1, v_input_ids_Q2, v_attention_mask_Q2)\n",
        "\n",
        "        # Compute Loss\n",
        "        loss = loss_fn(v_outQ1, v_outQ2, v_y)\n",
        "        v_loss.append(loss.item())\n",
        "    \n",
        "    # Compute averaged loss\n",
        "    avg_loss = np.mean(v_loss)\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def train_loop_Siamese(model, dataloader, validation, optimizer, scheduler, loss_fn, nepochs, device = None):\n",
        "    \n",
        "    for i_epoch in range(nepochs):\n",
        "        print(\"-----------------------------------------------------------------------------------------------\")\n",
        "        # Init\n",
        "        total_step_in_dataloader = len(dataloader)\n",
        "        epoch_time, batch_time = time.time(), time.time()\n",
        "        total_loss, batch_loss, batch_count = 0, 0, 0\n",
        "\n",
        "        # Put model in train mode (important if a run on the validation in eval mode have been done previously)\n",
        "        model.train()\n",
        "\n",
        "        # iterate over batches:\n",
        "        for step, batch in enumerate(dataloader):\n",
        "            \n",
        "            batch_count +=1\n",
        "\n",
        "            # Get batch data\n",
        "            input_ids_Q1 = batch[0]['input_ids'].to(device)\n",
        "            attention_mask_Q1 = batch[0]['attention_mask'].to(device)\n",
        "            input_ids_Q2 = batch[1]['input_ids'].to(device)\n",
        "            attention_mask_Q2 = batch[1]['attention_mask'].to(device)\n",
        "            y = batch[2].to(device)\n",
        "\n",
        "            # Reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Apply model\n",
        "            outQ1, outQ2 = model(input_ids_Q1, attention_mask_Q1, input_ids_Q2, attention_mask_Q2)\n",
        "\n",
        "            # Compute Constrastive loss\n",
        "            loss = loss_fn(outQ1, outQ2, y)\n",
        "\n",
        "            # Update batch loss and total loss\n",
        "            total_loss += loss.item()\n",
        "            batch_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Checking every 10 steps:\n",
        "            if ((((step + 1) % 5) == 0) and step != 0) or step == (total_step_in_dataloader - 1):\n",
        "                time_elapsed = str(timedelta(seconds = (time.time() - batch_time)))\n",
        "                batch_avg_loss = batch_loss/batch_count\n",
        "                print(f\"batch {step+1:>6d} / {total_step_in_dataloader:>4d} | Elapsed {time_elapsed} | Average loss on the previous {batch_count:>4d} batchs : {batch_avg_loss:5.2f} |\")\n",
        "\n",
        "                # Reset batch_count, batch_loss and batch_time\n",
        "                batch_loss, batch_count = 0, 0\n",
        "                batch_time = time.time()\n",
        "        \n",
        "        avg_train_loss_epoch = total_loss/total_step_in_dataloader\n",
        "        time_elapsed_epoch = str(timedelta(seconds = (time.time() - epoch_time)))\n",
        "        print(\"-----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        # Test current model ( at epcoch i ) on validation\n",
        "        if validation:\n",
        "            avg_validation_loss = evalute_Siamese(validation, model, loss_fn, device = device)\n",
        "            print(f\"Epoch {i_epoch+1:>6d} / {nepochs:>4d} | Elapsed {time_elapsed_epoch} | Average loss on epoch: {avg_train_loss_epoch:18.2f} | Average validation loss: {avg_validation_loss:6.2f}\")\n",
        "        else:\n",
        "            print(f\"Epoch {i_epoch+1:>6d} / {nepochs:>4d} | Elapsed {time_elapsed_epoch} | Average loss on epoch: {avg_train_loss_epoch:18.2f} |\")\n",
        "            \n",
        "\n",
        "    print(\"-----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "def cross_validation(model_class, dataset, k, loss_fn, batch_size = 8, nepochs = 4, device = None):\n",
        "\n",
        "    # Init kfold: split the dataset into k folds. shuffle = True indicates that the individuals of the different folds are chosen randomly and are not necesseraly packs that follow each others\n",
        "    kfold = KFold(n_splits = k, shuffle = True)\n",
        "\n",
        "    # Loop over folds: At each steps, (k - 1) folds are chosen to be in the training set and the remaining kième fold is chose to be the validation set.\n",
        "    for fold, (train_ids, validation_ids) in enumerate(kfold.split(dataset)):\n",
        "        print(\" --- fold: \" + str(fold) + \" --- \")\n",
        "        # To use the index of the individuals belonging to the (k - 1) training folds and the validation fold in the DataLoader, we create SubsetRandomSampler\n",
        "        # It creates a random sampler with the index in the (k - 1) training folds and the validation fold \n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        validation_subsampler = SubsetRandomSampler(validation_ids)\n",
        "\n",
        "        # We then create 2 data loader: one for iterative with batches over the train_ids and the second for the validation_ids\n",
        "        # We don't need to use shuffle in the DataLoader as the selection of the ids is done with the provided samplers train_subsampler and validation_subsampler\n",
        "        train_loader = DataLoader(dataset, batch_size, sampler = train_subsampler)\n",
        "        validation_loader = DataLoader(dataset, batch_size, sampler = validation_subsampler)\n",
        "        \n",
        "        # Now, train the model with the train_loader and evaludate it on the validation_loader\n",
        "        model = model_class()\n",
        "        # Check for cuda:\n",
        "        if device:\n",
        "          model.to(device)\n",
        "        optimizer, scheduler = init_model(model, train_loader, nepochs)\n",
        "        train_loop_Siamese(model, train_loader, validation_loader, optimizer, scheduler, loss_fn, nepochs, device = device)\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Wji21dYOd5",
        "outputId": "362b1008-ff33-46f1-85ad-242e74d7e0e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- fold: 0 --- \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "_train_dataset = SiameseNetWorkSentenceDataset(data = train.head(n = 100), tokenizer = tokenizer, max_length = 64)\n",
        "loss = ConstrastiveLoss(m = 10)\n",
        "cross_validation(model_class = SiameseBERTNet, dataset = _train_dataset, k = 5, loss_fn = loss, device = device)\n",
        "\n",
        "# TODO lancer la boucle de cross-validation pour tester le meiller m de la Contrastive loss ! On pourrait aussi l'utiliser pour le learning rate scheduler, etc ...\n",
        "# TODO tester aussi de faire une classif au seuil de distance m pour calculer TPR, FPR and accuracy!\n",
        "\n",
        "\n",
        "# For tests\n",
        "# model = SiameseBERTNet()\n",
        "\n",
        "# test_train_dataloader = DataLoader(test_train_dataset, batch_size = 8, shuffle = True, num_workers = 0)\n",
        "\n",
        "# nepochs = 4\n",
        "# \n",
        "# optimizer, scheduler = init_model(model, test_train_dataloader, nepochs)\n",
        "# train_loop_Siamese(model, test_train_dataloader, optimizer, scheduler, loss, nepochs)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "19c1444b3d5567e4cbdf4788d938f6edea2231b6a36cad91fb20378c11783a94"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('QQP': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2,
    "colab": {
      "name": "notebook_qqp.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}