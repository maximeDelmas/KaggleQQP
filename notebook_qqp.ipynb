{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statistics\n",
    "from transformers import BertTokenizer, BertForPreTraining, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilitary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(dataset):\n",
    "    \n",
    "    # Check is all questions in 'question1' and 'question2' are str\n",
    "    filter = np.array([not isinstance(s1, str) for s1 in dataset['question1'].tolist()]) | np.array([not isinstance(s2, str) for s2 in dataset['question2'].tolist()])\n",
    "    indexes_to_drop = dataset[filter].index\n",
    "    \n",
    "    # drop lines that are not\n",
    "    if not len(indexes_to_drop):\n",
    "        print(\"All rows are corrects\")\n",
    "    else:\n",
    "        print(\"Removing the following lines: \")\n",
    "        print(dataset.loc[indexes_to_drop])\n",
    "        dataset = dataset.drop(indexes_to_drop)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following lines: \n",
      "          qid1    qid2                         question1  \\\n",
      "id                                                         \n",
      "105780  174363  174364    How can I develop android app?   \n",
      "201841  303951  174364  How can I create an Android app?   \n",
      "363362  493340  493341                               NaN   \n",
      "\n",
      "                                                question2  is_duplicate  \n",
      "id                                                                       \n",
      "105780                                                NaN             0  \n",
      "201841                                                NaN             0  \n",
      "363362  My Chinese name is Haichao Yu. What English na...             0  \n",
      "Removing the following lines: \n",
      "                                           question1  \\\n",
      "test_id                                                \n",
      "379205      How I can learn android app development?   \n",
      "817520   How real can learn android app development?   \n",
      "943911                          How app development?   \n",
      "1046690                                          NaN   \n",
      "1270024             How I can learn app development?   \n",
      "1461432                                          NaN   \n",
      "\n",
      "                                               question2  \n",
      "test_id                                                   \n",
      "379205                                               NaN  \n",
      "817520                                               NaN  \n",
      "943911                                               NaN  \n",
      "1046690    How I what can learn android app development?  \n",
      "1270024                                              NaN  \n",
      "1461432  How distinct can learn android app development?  \n"
     ]
    }
   ],
   "source": [
    "# Paths & Variables\n",
    "\n",
    "data_path = \"data/quora-question-pairs\"\n",
    "train_file = \"train.csv\"\n",
    "test_pos_file = \"test.csv\"\n",
    "label_file = \"sample_submission.csv\"\n",
    "\n",
    "# Reading\n",
    "train = pd.read_csv(os.path.join(data_path, train_file), index_col = 0)\n",
    "test_pos = pd.read_csv(os.path.join(data_path, test_pos_file), index_col = 0)\n",
    "y_label = pd.read_csv(os.path.join(data_path, label_file), index_col = 0)\n",
    "\n",
    "# Fix datasets for NaN values in question1 or question2\n",
    "train = fix_dataset(train)\n",
    "test_pos = fix_dataset(test_pos)\n",
    "\n",
    "# join test and y_label\n",
    "test_pos = test_pos.join(y_label, on = 'test_id', how = 'left')\n",
    "\n",
    "# test set contains only positive, labels; suffle to create negative examples\n",
    "test_neg = test_pos.copy()\n",
    "test_neg['question1'] = np.random.permutation(test_neg['question1'])\n",
    "test_neg['is_duplicate'] = 0\n",
    "\n",
    "# Create final test set\n",
    "test = pd.concat([test_pos, test_neg], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "\n",
    "See (https://paperswithcode.com/method/wordpiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id for [CLS]: 101\n",
      "Token id for [SEP]: 102\n",
      "Token id for [PAD]: 0\n",
      "Token id for [UNK]: 100\n",
      "Token id for [MASK]: 103\n",
      "Original sentense: What is the step by step guide to invest in share market in india?\n",
      "Encoded sentense: \n",
      "[101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029, 102]\n",
      "Decoded sentense: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 11:37:43.333556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:\n",
      "2022-01-18 11:37:43.333579: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] what is the step by step guide to invest in share market in india? [SEP]\n",
      "La taille maximale de tokens est 286 (avec les [CLS] et [SEP])\n",
      "Il y a 99.88% des phrases tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Token id for [CLS]: \" + str(tokenizer.cls_token_id))\n",
    "print(\"Token id for [SEP]: \" + str(tokenizer.sep_token_id))\n",
    "print(\"Token id for [PAD]: \" + str(tokenizer.pad_token_id))\n",
    "print(\"Token id for [UNK]: \" + str(tokenizer.unk_token_id))\n",
    "print(\"Token id for [MASK]: \" + str(tokenizer.mask_token_id))\n",
    "\n",
    "print(\"Original sentense: \" + train.loc[0, 'question1'])\n",
    "print(\"Encoded sentense: \")\n",
    "enc = tokenizer.encode(train.loc[0, 'question1'])\n",
    "print(enc)\n",
    "print(\"Decoded sentense: \")\n",
    "dec = tokenizer.decode(enc)\n",
    "print(dec)\n",
    "\n",
    "# Check len of tokenized training sentences:\n",
    "list_len = []\n",
    "all_s = train['question1'].tolist() + train['question2'].tolist()\n",
    "for s in all_s:\n",
    "    tks = tokenizer.encode(s)\n",
    "    list_len.append(len(tks))\n",
    "\n",
    "max_len = max(list_len)\n",
    "\n",
    "print(f\"La taille maximale de tokens est {max_len} (avec les [CLS] et [SEP])\")\n",
    "lw_64 = round((sum([l <= 64 for l in list_len])/len(list_len)) * 100, 2) \n",
    "print(f\"Il y a {lw_64}% des phrases tokenised qui sont <= 64. C'est suffisant, on supprimera celle plus grande du dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "See https://pytorch.org/tutorials/beginner/basics/data_tutorial.html for documentation about the Dataset and Dataloader creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetWorkSentenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    SiameseNetWorkSentenceDataset create a Dataset\n",
    "    - data (pd.DataFrame): the data dataframe with column 'question1' and 'question2' along with the label 'is_duplicate'\n",
    "    - tokenizer: the BERT tokenizer, such as: BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    - max_length: the maximal length of tokens input vector (default 64) Shorter vector arre padded to max_length with [PAD token] (id: 0) and longer are truncated. \n",
    "    The size includes the start [CLS] and end [SEP] tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        def squeeze_tensors(tks):\n",
    "            \"\"\"Take a tensor and remove unnecessary dimension. When using tokenizer with return_tensors = 'pt', the returned tensor is by default 2 dimensions, has it could handle a list of sentence as inputs.\n",
    "            However, as we only sent one sentence at a time to the tokenizer to create the Dataset, it result in an additional dimension that will be useless after pooling results by batches in the DataLoader\n",
    "\n",
    "            Args:\n",
    "                tks ([type]): [description]\n",
    "            \"\"\"\n",
    "            tks.data[\"input_ids\"] = torch.squeeze(tks.data[\"input_ids\"])\n",
    "            tks.data[\"token_type_ids\"] = torch.squeeze(tks.data[\"token_type_ids\"])\n",
    "            tks.data[\"attention_mask\"] = torch.squeeze(tks.data[\"attention_mask\"])\n",
    "\n",
    "        s1 = self.data.loc[index, 'question1']\n",
    "        s2 = self.data.loc[index, 'question2']\n",
    "        label = torch.tensor(self.data.loc[index, 'is_duplicate'])\n",
    "\n",
    "        tokens1 = self.tokenizer(text = s1, max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
    "        squeeze_tensors(tokens1)\n",
    "        tokens2 = self.tokenizer(text = s2, max_length = self.max_length, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
    "        squeeze_tensors(tokens2)\n",
    "\n",
    "        return tokens1, tokens2, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([  101,  4118,  2000,  2424,  8745,  1997, 29199,  2478, 10424,  2229,\n",
      "        11877, 12170, 18098,  2964,  1029,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, {'input_ids': tensor([  101,  2054,  2024,  2070,  1997,  1996,  2477, 20202,  2064,  2425,\n",
      "         2055,  1996,  4241,  2527,  8553,  1998, 15258,  1997, 12191,  2015,\n",
      "         1998,  2049,  6177,  1029,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, tensor(0))\n",
      "404287\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = SiameseNetWorkSentenceDataset(data = train, tokenizer = tokenizer, max_length = 64)\n",
    "print(train_dataset[10])\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size = 8, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseBERTNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseBERTNet, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.HS = self.bert.config.hidden_size\n",
    "\n",
    "    def forward_siamese(self, input, noCLSpooling = True, noSEPpooling = True):\n",
    "        \"\"\"From tokenised input sentence, compute BERT \n",
    "\n",
    "        Args:\n",
    "            input (dict): output dict from the tokenizer with input_ids, token_type_ids and attention_mask\n",
    "\n",
    "        Returns:\n",
    "            avg (tensor): Mean of the last hidden layer vectors for real tokens (attention_mask: 1) in the input.\n",
    "        \"\"\"\n",
    "        # Get input_ids and attention mask\n",
    "        input_ids, token_type_ids, attention_mask = input.values()\n",
    "\n",
    "        # Apply BERT and extract last_hidden_state\n",
    "        out = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        last_hidden_state = out.last_hidden_state\n",
    "\n",
    "        # Apply mean pooling on real tokens\n",
    "        # Make a copy is some changes (CLS or SEP) need to be applied\n",
    "        pooling_mask = attention_mask.detach().clone()\n",
    "\n",
    "        # If the CLS output vector should not participate in average pooling\n",
    "        if noCLSpooling:\n",
    "            pooling_mask[:, 0] = 0\n",
    "        \n",
    "        # If the SEP output vector should not participate in average pooling\n",
    "        if noSEPpooling:\n",
    "            pooling_mask = torch.where(input_ids == 102, 0, pooling_mask)\n",
    "\n",
    "        # Get mask at the same dimension as last_hidden_state\n",
    "        expanded_pooling_mask = pooling_mask.unsqueeze(-1)\n",
    "        expanded_pooling_mask = expanded_pooling_mask.expand(-1, -1, self.HS)\n",
    "\n",
    "        # Element wise mul between last_hidden_state and mask to then only consider real tokens in the sum\n",
    "        prod = torch.mul(last_hidden_state, expanded_pooling_mask)\n",
    "\n",
    "        # Sum all token vectors\n",
    "        sum_by_tks = torch.sum(prod, dim = 1)\n",
    "\n",
    "        # Get normalisation factor to compute mean\n",
    "        norm = torch.sum(pooling_mask, dim = -1).unsqueeze(-1)\n",
    "\n",
    "        # Comptue average\n",
    "        avg = torch.div(sum_by_tks, norm)\n",
    "\n",
    "        return avg\n",
    "\n",
    "\n",
    "    def forward(self, question1, question2):\n",
    "        out1 = self.forward_siamese(question1)\n",
    "        out2 = self.forward_siamese(question2)\n",
    "\n",
    "        return out1, out2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SiameseBERTNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4299, -0.2941, -0.0675,  ..., -0.1354,  0.3433, -0.1303],\n",
       "         [-0.2913, -0.3231,  0.3012,  ..., -0.2725,  0.4931, -0.2576],\n",
       "         [ 0.0685, -0.0801,  0.4622,  ..., -0.4811, -0.0436,  0.0921],\n",
       "         ...,\n",
       "         [ 0.0229, -0.0395,  0.2465,  ..., -0.1411, -0.0208,  0.4178],\n",
       "         [ 0.1411, -0.3166, -0.1117,  ..., -0.2730,  0.2925,  0.2480],\n",
       "         [ 0.2395,  0.0070,  0.0455,  ..., -0.1985,  0.0763,  0.2774]],\n",
       "        grad_fn=<DivBackward0>),\n",
       " tensor([[ 0.4390, -0.3143, -0.2842,  ...,  0.0353,  0.1169, -0.2412],\n",
       "         [-0.3177, -0.2250,  0.3498,  ..., -0.4351,  0.3755, -0.2483],\n",
       "         [-0.0074,  0.1461,  0.5292,  ..., -0.4827, -0.0031, -0.1812],\n",
       "         ...,\n",
       "         [-0.1986,  0.0688,  0.0607,  ..., -0.2054,  0.1053,  0.1306],\n",
       "         [ 0.1292, -0.1880, -0.0761,  ..., -0.4151,  0.3113,  0.3144],\n",
       "         [ 0.2097,  0.2462, -0.0774,  ..., -0.0744,  0.0023,  0.4150]],\n",
       "        grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = next(iter(dataloader))\n",
    "model(test[0], test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BERT embedding without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "How does the Surface Pro himself 4 compare with iPad Pro?"
          ],
          [
           "Should I have a hair transplant at age 24? How much would it cost?"
          ],
          [
           "What but is the best way to send money from China to the US?"
          ],
          [
           "Which food not emulsifiers?"
          ],
          [
           "How \"aberystwyth\" start reading?"
          ],
          [
           "How are the two wheeler insurance from Bharti Axa insurance?"
          ],
          [
           "How can I reduce my belly fat through a diet?"
          ],
          [
           "By scrapping the 500 and 1000 rupee notes, how is RBI planning to fight against issue black money?"
          ],
          [
           "What are the how best books of all time?"
          ],
          [
           "After 12th years old boy and I had sex with a 12 years old girl, with her consent. Is there anything wrong?"
          ],
          [
           "Prefer some good University in Banglore to do MBA in distance education?"
          ],
          [
           "What is the corporate culture like at Cabot? How is the culture different than other writing?"
          ],
          [
           "Can the penis size cricket or girth) be permanently increased?"
          ],
          [
           "What is your one on the move to scrap 500 and 1000 rupee notes? What will be its effects?"
          ],
          [
           "Is UPES in Dehradun a good ways?"
          ],
          [
           "How do I get rid tripadvisor the feeling of being nervous?"
          ],
          [
           "Does Burj Khalifa consists of apartments? If yes, kind costly are they?"
          ],
          [
           "What it's like to easiest in prison?"
          ],
          [
           "How accounts I increase my phone's RAM from 555 MB to 1 GB or more?"
          ],
          [
           "Bollywood: Why do stem credits of Dil Dhadakne have credits from Zindagi Na Milegi Dobara? See image?"
          ],
          [
           "Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?"
          ],
          [
           "How much cost does hair transplant require?"
          ],
          [
           "What you send money to China?"
          ],
          [
           "What foods fibre?"
          ],
          [
           "How their can I start reading?"
          ],
          [
           "I admire I am considering of buying insurance from them"
          ],
          [
           "How can I reduce my lower belly fat in one month?"
          ],
          [
           "How will the recent move to declare 500 and 1000 denomination lewin illegal will curb black money?"
          ],
          [
           "What are some of the military history books of all time?"
          ],
          [
           "Can a 14 old guy date a 12 year old girl?"
          ],
          [
           "What are the hair for my birthday?"
          ],
          [
           "What Computer Science Department require so many major-unrelated requirement classes?"
          ],
          [
           "Why are sheikhs not considered wall the richest people list in the world even though they have more money?"
          ],
          [
           "I am working in an IT company with 9 hours side work. Is it possible for me to crack the GATE in electrical engineering?"
          ],
          [
           "What are the types of models used in Cost Centers?"
          ],
          [
           "What is the most study scene in twin peaks?"
          ],
          [
           "How question FedEx packages delivered?"
          ],
          [
           "Can a non-alcoholic restaurant be a huge success?"
          ],
          [
           "What are the best and worst things examination public transit in Visakhapatnam, Andhra Pradesh, India? How could it be improved?"
          ],
          [
           "How do I out get rid of Erectile Dysfunction?"
          ]
         ],
         "hovertemplate": "X=%{x}<br>Y=%{y}<br>question=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.3340813219547272,
          2.722334146499634,
          -0.22672253847122192,
          1.4577381610870361,
          0.09158001840114594,
          -1.9172797203063965,
          3.808215856552124,
          -1.318779706954956,
          2.108717918395996,
          -1.665217638015747,
          -3.2980988025665283,
          0.07490423321723938,
          1.524770736694336,
          -0.1549646407365799,
          -1.6450304985046387,
          1.83400559425354,
          -1.1832119226455688,
          0.8824238181114197,
          0.7423125505447388,
          -1.2697418928146362,
          -0.9730488061904907,
          2.8537049293518066,
          0.34010156989097595,
          2.6157445907592773,
          3.909048557281494,
          -1.0723954439163208,
          3.412715435028076,
          -0.3426438271999359,
          1.6055114269256592,
          -0.028604716062545776,
          3.5169310569763184,
          0.19711026549339294,
          -0.7865358591079712,
          -0.5065300464630127,
          1.0355924367904663,
          0.8886207938194275,
          0.33938729763031006,
          1.2159086465835571,
          -0.8823385834693909,
          3.0746541023254395
         ],
         "xaxis": "x",
         "y": [
          -0.34796255826950073,
          1.3155722618103027,
          -2.220386028289795,
          -0.3363226652145386,
          -0.10390482097864151,
          -0.21803386509418488,
          2.0586023330688477,
          -0.2600167393684387,
          -4.4085283279418945,
          2.071744203567505,
          1.402925729751587,
          -1.1149557828903198,
          1.099422574043274,
          -1.4913761615753174,
          -0.9786420464515686,
          0.5960376858711243,
          -0.6255234479904175,
          -2.1393074989318848,
          0.6107038259506226,
          0.4526591897010803,
          -0.12399321794509888,
          -0.256131649017334,
          -3.7852444648742676,
          -1.957435965538025,
          0.10779081284999847,
          0.09800923615694046,
          2.1869378089904785,
          -0.7607802152633667,
          -4.133357048034668,
          2.3844518661499023,
          -1.2589346170425415,
          -0.04328513145446777,
          -1.1183865070343018,
          1.4141364097595215,
          -2.4097115993499756,
          -0.9810040593147278,
          -2.3101253509521484,
          1.6670101881027222,
          -0.1729847639799118,
          1.8435049057006836
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "X"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a set of sample sentenses from test set:\n",
    "\n",
    "positives_s = test.head(n = 10)\n",
    "negatives_s = test.tail(n = 10)\n",
    "\n",
    "all_s = positives_s.append(negatives_s, ignore_index = True)\n",
    "all_s.to_csv(\"data/sample.csv\", index = False)\n",
    "d = SiameseNetWorkSentenceDataset(data = all_s, tokenizer = tokenizer, max_length = 64)\n",
    "l = DataLoader(d, batch_size = 20, shuffle = False, num_workers = 0)\n",
    "sample = next(iter(l))\n",
    "res = model(sample[0], sample[1])\n",
    "res = torch.cat([res[0], res[1]], axis = 0)\n",
    "\n",
    "# Compute PCA\n",
    "U, S, V = torch.pca_lowrank(res, niter = 50)\n",
    "proj = torch.matmul(res, V[:, :2])\n",
    "\n",
    "plot_data = pd.DataFrame(proj.detach().numpy())\n",
    "plot_data[\"question\"] = (all_s[\"question1\"].tolist() + all_s[\"question2\"].tolist())\n",
    "plot_data = plot_data.rename({0: 'X', 1: 'Y'}, axis=1)\n",
    "\n",
    "fig = px.scatter(plot_data, x = \"X\", y = \"Y\", hover_data=['question'])\n",
    "fig.show()\n",
    "\n",
    "# Compute distance matrix :\n",
    "D = torch.cdist(res.double(), res.double(), p = 2)\n",
    "df = pd.DataFrame(D.detach().numpy().round(3))\n",
    "df.to_csv(\"data/NormEucDistanceMatrix_1.csv\", index = False, header = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19c1444b3d5567e4cbdf4788d938f6edea2231b6a36cad91fb20378c11783a94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('QQP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
